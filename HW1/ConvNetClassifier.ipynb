{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field()\n",
    "LABEL = torchtext.data.Field(sequential=False)\n",
    "train, val, test = torchtext.datasets.SST.splits(\n",
    "    TEXT, LABEL,\n",
    "    filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "n_vocab = len(TEXT.vocab)\n",
    "\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
    "n_comps = TEXT.vocab.vectors.size(1)\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train, val, test), batch_size=BATCH_SIZE, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNetClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vecs, dropout_rate=0.5):\n",
    "        super(ConvNetClassifier, self).__init__()\n",
    "        self.vecs = vecs\n",
    "        self.conv3 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(3, n_comps))\n",
    "        self.conv4 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(4, n_comps))\n",
    "        self.conv5 = nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, n_comps))\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout2d(p=dropout_rate)\n",
    "        self.linear = nn.Linear(300, 1)\n",
    "    \n",
    "    def forward(self, text, training=False):\n",
    "        while text.size(0) < 5:\n",
    "            text = torch.cat([text, torch.ones((1, text.size(1))).long()], 0)\n",
    "        sent_length, batch_size = text.size()\n",
    "        X = self.vecs[text.data.view(-1,)].view(sent_length, batch_size, n_comps)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        X = X.data.unsqueeze_(1)\n",
    "        X = Variable(X)\n",
    "        \n",
    "        # Extract and pool convolutional features\n",
    "        X3 = F.relu(self.conv3(X))\n",
    "        X3 = F.max_pool2d(X3, (X3.size(2), 1))\n",
    "        X4 = F.relu(self.conv4(X))\n",
    "        X4 = F.max_pool2d(X4, (X4.size(2), 1))\n",
    "        X5 = F.relu(self.conv5(X))\n",
    "        X5 = F.max_pool2d(X5, (X5.size(2), 1))\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        if training:\n",
    "            X3 = self.dropout(X3)\n",
    "            X4 = self.dropout(X4)\n",
    "            X5 = self.dropout(X5) \n",
    "        \n",
    "        # Final layer\n",
    "        X = torch.cat([X3, X4, X5], 1).squeeze()\n",
    "        probs = F.sigmoid(self.linear(X))\n",
    "        return torch.cat([probs, 1-probs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0: 0.5692576766014099\n",
      "Iteration #1: 0.5276330709457397\n",
      "Iteration #2: 0.4444142282009125\n",
      "Iteration #3: 0.4883195161819458\n",
      "Iteration #4: 0.3524026572704315\n",
      "Iteration #5: 0.3241563141345978\n",
      "Iteration #6: 0.42746302485466003\n",
      "Iteration #7: 0.19237355887889862\n",
      "Iteration #8: 0.2106371819972992\n",
      "Iteration #9: 0.08412794768810272\n",
      "Iteration #10: 0.060294173657894135\n",
      "Iteration #11: 0.21543025970458984\n",
      "Iteration #12: 0.09555546939373016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-c5acd3c697ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-39e6e4b81b18>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, training)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Extract and pool convolutional features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mX4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vecs = Variable(TEXT.vocab.vectors, requires_grad=True)\n",
    "cn = ConvNetClassifier(vecs)\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(cn.parameters(), lr=0.001)\n",
    "optimizer2 = optim.Adam([cn.vecs], lr=0.0001)\n",
    "#optimizer = optim.SGD(cn.parameters(), lr=0.03, weight_decay=0.01)\n",
    "#optimizer = optim.Adadelta(cn.parameters(), lr=0.1)\n",
    "#max_vec_size = 5\n",
    "\n",
    "for i in range(100):\n",
    "    train_iter.init_epoch()\n",
    "    for batch in train_iter:\n",
    "        cn.zero_grad()\n",
    "        probs = cn(batch.text, training=True)\n",
    "        log_probs = torch.log(probs)\n",
    "        y = batch.label - 1\n",
    "        loss = loss_function(log_probs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         optimizer2.step()\n",
    "        \n",
    "        # Regularization\n",
    "#         for w in cn.parameters():\n",
    "#             w_2norm = w.data.norm(2)\n",
    "#             if w_2norm > max_vec_size:\n",
    "#                 w.data = max_vec_size / w_2norm * w.data\n",
    "    print('Iteration #{}: {}'.format(i, loss.data.numpy()[0]))\n",
    "#cn.linear.weight.data *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cn.linear.weight.data *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "train_iter.init_epoch()\n",
    "for batch in train_iter:\n",
    "    lengths.append(batch.text.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_iter):\n",
    "    data_iter.init_epoch()\n",
    "    N = len(data_iter.data())\n",
    "    n_correct = 0\n",
    "    data_iter.init_epoch()\n",
    "    for batch in data_iter:\n",
    "        probs = model(batch.text)\n",
    "        _, y_predicted = probs.max(1)\n",
    "        y_true = batch.label - 1\n",
    "        n_correct += (y_true == y_predicted).sum().float()\n",
    "    return (n_correct / N).data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99407512"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(cn, train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78583199"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(cn, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.999999962180317"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.linear.weight.data.norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_linear.weight.data = test_linear.weight.data * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4999999810901585"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.linear.weight.data.norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       " 0.0919  0.0995 -0.0591 -0.0713 -0.0962 -0.0985 -0.0943 -0.0954  0.0753 -0.0675\n",
       "\n",
       "Columns 10 to 19 \n",
       "-0.0731 -0.0407 -0.0846  0.0974 -0.0862 -0.0913  0.0820 -0.0800  0.0970  0.0920\n",
       "\n",
       "Columns 20 to 29 \n",
       " 0.0867  0.0855 -0.0874  0.1046  0.0522  0.1021 -0.0905 -0.0797  0.0556 -0.0818\n",
       "\n",
       "Columns 30 to 39 \n",
       "-0.0948 -0.0248  0.0984  0.0363 -0.0818 -0.0781 -0.0681  0.0765 -0.0971  0.0563\n",
       "\n",
       "Columns 40 to 49 \n",
       "-0.0753 -0.1091 -0.0936 -0.0554 -0.0742 -0.0950 -0.1096  0.0906 -0.0903 -0.0933\n",
       "\n",
       "Columns 50 to 59 \n",
       "-0.0866 -0.0796 -0.0287 -0.0763 -0.1002 -0.0852 -0.0730 -0.0770 -0.1007  0.0883\n",
       "\n",
       "Columns 60 to 69 \n",
       "-0.0883 -0.1000 -0.0548 -0.0860  0.0809 -0.0816  0.0910 -0.0962  0.0917  0.0973\n",
       "\n",
       "Columns 70 to 79 \n",
       "-0.0786  0.1067  0.0942  0.0807 -0.0860 -0.0528  0.0952  0.0870  0.0752 -0.0895\n",
       "\n",
       "Columns 80 to 89 \n",
       "-0.1118  0.0762  0.0893 -0.0818  0.0850 -0.1047 -0.1015  0.0950  0.0759 -0.0389\n",
       "\n",
       "Columns 90 to 99 \n",
       "-0.0879 -0.0937  0.0425 -0.0923 -0.0821 -0.0937  0.0584 -0.0809  0.0729  0.0951\n",
       "\n",
       "Columns 100 to 109 \n",
       " 0.1009  0.0434  0.1032  0.1031  0.0406  0.0810  0.0463  0.0994 -0.0863 -0.0649\n",
       "\n",
       "Columns 110 to 119 \n",
       " 0.0838 -0.0963  0.0904 -0.0873 -0.0883 -0.0983 -0.1001 -0.0943  0.0742 -0.1022\n",
       "\n",
       "Columns 120 to 129 \n",
       " 0.1043 -0.0919  0.0987 -0.0922  0.0425  0.0977  0.0836 -0.0995 -0.1021  0.0655\n",
       "\n",
       "Columns 130 to 139 \n",
       "-0.0943  0.0890  0.0972 -0.0934  0.1019  0.0910  0.0870  0.0901 -0.0552  0.0632\n",
       "\n",
       "Columns 140 to 149 \n",
       "-0.0983 -0.0920 -0.1028 -0.0535  0.0921 -0.0871 -0.1036  0.0701 -0.0725 -0.0771\n",
       "\n",
       "Columns 150 to 159 \n",
       " 0.0866  0.0847 -0.0785  0.0738  0.0834  0.1103 -0.0945  0.0867  0.0832 -0.0960\n",
       "\n",
       "Columns 160 to 169 \n",
       "-0.1006 -0.0687  0.0942  0.0906  0.0793 -0.0861 -0.1050 -0.1055 -0.0771  0.0821\n",
       "\n",
       "Columns 170 to 179 \n",
       "-0.1031  0.0882 -0.0847 -0.1069 -0.0836 -0.0421  0.1019  0.0839  0.0647  0.0081\n",
       "\n",
       "Columns 180 to 189 \n",
       "-0.0956 -0.0720  0.1049  0.0945  0.0856 -0.0892 -0.1035  0.0582  0.0769 -0.0835\n",
       "\n",
       "Columns 190 to 199 \n",
       " 0.0753 -0.0867  0.0592  0.0980 -0.0409 -0.0832  0.0836  0.0753  0.1044 -0.0984\n",
       "\n",
       "Columns 200 to 209 \n",
       " 0.0962 -0.0877  0.0968  0.0862 -0.0942 -0.1021 -0.0914  0.0893 -0.0820 -0.1046\n",
       "\n",
       "Columns 210 to 219 \n",
       " 0.0955 -0.0604  0.0620 -0.1077 -0.1064  0.0711  0.0904  0.0653 -0.0998  0.1007\n",
       "\n",
       "Columns 220 to 229 \n",
       "-0.1003  0.0681 -0.0985 -0.0557 -0.0882  0.0820 -0.0721 -0.0328  0.0917  0.0618\n",
       "\n",
       "Columns 230 to 239 \n",
       " 0.0944 -0.1070  0.0823  0.0744 -0.1107  0.0865 -0.0938  0.0878 -0.1064  0.0903\n",
       "\n",
       "Columns 240 to 249 \n",
       " 0.0836 -0.0854 -0.0698  0.0773  0.1079  0.1030  0.0835 -0.0589 -0.0946  0.0931\n",
       "\n",
       "Columns 250 to 259 \n",
       " 0.0745  0.0960  0.0870 -0.0841 -0.0886  0.0692 -0.0923  0.0963  0.1012  0.0867\n",
       "\n",
       "Columns 260 to 269 \n",
       " 0.0924  0.1071 -0.0491  0.0796 -0.0439 -0.1018  0.0857  0.1013  0.0940  0.0934\n",
       "\n",
       "Columns 270 to 279 \n",
       "-0.0955  0.0983  0.0992  0.0993  0.0863  0.0977 -0.1029  0.0944  0.0838 -0.0993\n",
       "\n",
       "Columns 280 to 289 \n",
       " 0.0956 -0.0939 -0.0886  0.0667 -0.0988 -0.0767  0.0654  0.0906 -0.0900  0.0935\n",
       "\n",
       "Columns 290 to 299 \n",
       " 0.0747  0.0918 -0.0724  0.1002  0.1058  0.1067  0.0762 -0.0973 -0.0466  0.0732\n",
       "[torch.FloatTensor of size 1x300]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = cn.linear.weight * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_vec_size = 3\n",
    "w_2norm = cn.linear.weight.data.norm(2)\n",
    "cn.linear.weight.data = max_vec_size / w_2norm * cn.linear.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot assign 'torch.autograd.variable.Variable' as parameter 'weight' (torch.nn.Parameter or None expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-8ab163ff9165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 raise TypeError(\"cannot assign '{}' as parameter '{}' \"\n\u001b[1;32m    280\u001b[0m                                 \u001b[0;34m\"(torch.nn.Parameter or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                                 .format(torch.typename(value), name))\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot assign 'torch.autograd.variable.Variable' as parameter 'weight' (torch.nn.Parameter or None expected)"
     ]
    }
   ],
   "source": [
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = f.weight * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Variable objects containing non-empty torch.ByteTensor is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-338bb810f20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mn_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         raise RuntimeError(\"bool value of Variable objects containing non-empty \" +\n\u001b[0;32m--> 123\u001b[0;31m                            torch.typename(self.data) + \" is ambiguous\")\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Variable objects containing non-empty torch.ByteTensor is ambiguous"
     ]
    }
   ],
   "source": [
    "test_iter.init_epoch()\n",
    "N = len(test_iter.data())\n",
    "n_correct = 0\n",
    "test_iter.init_epoch()\n",
    "for batch in test_iter:\n",
    "    probs = cn(batch.text)\n",
    "    _, y_predicted = probs.max(1)\n",
    "    y_true = batch.label - 1\n",
    "    if (y_true == y_predicted).sum() != 50:\n",
    "        raise ValueError()\n",
    "    n_correct += (y_true == y_predicted).sum().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3969\n",
       " 0.4813\n",
       " 0.5928\n",
       " 0.4208\n",
       " 0.4645\n",
       " 0.2857\n",
       "[torch.FloatTensor of size 6]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:, 0][~(y_true == y_predicted).data]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
