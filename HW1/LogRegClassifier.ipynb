{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field()\n",
    "LABEL = torchtext.data.Field(sequential=False)\n",
    "train, val, test = torchtext.datasets.SST.splits(\n",
    "    TEXT, LABEL,\n",
    "    filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "n_vocab = len(TEXT.vocab)\n",
    "vecs = torch.eye(n_vocab)\n",
    "vecs[:, 1] = 0 # ignore <pad>\n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi, vecs, n_vocab)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train, val, test), batch_size=BATCH_SIZE, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogRegClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(LogRegClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(vocab_size, 1)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # Create design matrix\n",
    "        vecs = []\n",
    "        for b in range(text.size(1)):\n",
    "            v = TEXT.vocab.vectors[text.data[:, b]].max(0)[0]\n",
    "            vecs.append(v.view(1, -1))\n",
    "        X = Variable(torch.cat(vecs))\n",
    "        p = F.sigmoid(self.linear(X))\n",
    "        return torch.cat([p, 1-p], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_iter):\n",
    "    data_iter.init_epoch()\n",
    "    N = len(data_iter.data())\n",
    "    n_correct = 0\n",
    "    data_iter.init_epoch()\n",
    "    for batch in data_iter:\n",
    "        probs = model(batch.text)\n",
    "        _, y_predicted = probs.max(1)\n",
    "        y_true = batch.label - 1\n",
    "        n_correct += (y_true == y_predicted).sum().float()\n",
    "    return (n_correct / N).data.numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.001\n",
      "0.0001\n",
      "1e-05\n",
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "acc = {}\n",
    "regs = [10**-2, 10**-3, 10**-4, 10**-5, 10**-6]\n",
    "for reg in regs:\n",
    "    lr = LogRegClassifier(n_vocab)\n",
    "    loss_function = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(lr.parameters(), lr=0.01, weight_decay=reg)\n",
    "\n",
    "    for _ in range(10):\n",
    "        train_iter.init_epoch()\n",
    "        for batch in train_iter:\n",
    "            lr.zero_grad()\n",
    "            probs = lr(batch.text)\n",
    "            log_probs = torch.log(probs)\n",
    "            y = batch.label - 1\n",
    "            loss = loss_function(log_probs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(reg)\n",
    "    train_acc = evaluate(lr, train_iter)\n",
    "    val_acc = evaluate(lr, val_iter)\n",
    "    acc[reg] = {'train': train_acc, 'val': val_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-06: {'train': 0.98843932, 'val': 0.79243118},\n",
       " 1e-05: {'train': 0.98800576, 'val': 0.79816514},\n",
       " 0.0001: {'train': 0.98208094, 'val': 0.79701835},\n",
       " 0.001: {'train': 0.9105491, 'val': 0.77064222},\n",
       " 0.01: {'train': 0.74104047, 'val': 0.70412844}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_sentence(sent):\n",
    "    words = re.findall(r\"[\\w']+|[.,!?;]\", sent)\n",
    "    ints = [TEXT.vocab.stoi[w] for w in words]\n",
    "    probs = lr(Variable(torch.LongTensor(ints)).view(-1, 1)).data.numpy()\n",
    "    if probs[0, 0] > probs[0, 1]:\n",
    "        print('This is a positive sentence :D')\n",
    "    else:\n",
    "        print('This is a negative sentence :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a positive sentence :D\n"
     ]
    }
   ],
   "source": [
    "evaluate_sentence(\"I fucking hate you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogRegClassifier (\n",
       "  (linear): Linear (16284 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
