{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, DE, EN = load_data(max_len=20, min_freq=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_vocab_size, dec_vocab_size, enc_embed_dim, dec_embed_dim, hidden_size,\n",
    "                 enc_num_layers, dec_num_layers):\n",
    "        # Save hyperparameters\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.enc_vocab_size = enc_vocab_size\n",
    "        self.dec_vocab_size = dec_vocab_size\n",
    "        self.enc_embed_dim = enc_embed_dim\n",
    "        self.dec_embed_dim = dec_embed_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.enc_num_layers = enc_num_layers\n",
    "        self.dec_num_layers = dec_num_layers\n",
    "        \n",
    "        # Layers\n",
    "        self.enc_embedding = nn.Embedding(enc_vocab_size, enc_embed_dim)\n",
    "        self.enc_lstm = nn.LSTM(input_size=enc_embed_dim, hidden_size=hidden_size, num_layers=enc_num_layers)\n",
    "        self.dec_embedding = nn.Embedding(dec_vocab_size, dec_embed_dim)\n",
    "        self.dec_lstm = nn.LSTM(input_size=dec_embed_dim, hidden_size=hidden_size, num_layers=dec_num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, dec_vocab_size)\n",
    "        \n",
    "        # Weight initialization\n",
    "        for p in self.enc_lstm.parameters():\n",
    "            p.data.uniform_(-0.08, 0.08)\n",
    "        for p in self.dec_lstm.parameters():\n",
    "            p.data.uniform_(-0.08, 0.08)\n",
    "    \n",
    "    def forward(self, src, trg):        \n",
    "        # Encoder\n",
    "        enc_input = self.enc_embedding(src)\n",
    "        _, hidden = self.enc_lstm(enc_input)\n",
    "        \n",
    "        # Decoder\n",
    "        dec_input = self.dec_embedding(trg)\n",
    "        output, _ = self.dec_lstm(dec_input, hidden)\n",
    "        output = self.linear(output)\n",
    "        log_probs = F.log_softmax(output, dim=2)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = EN.vocab.stoi[EN.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s2s = Seq2Seq(enc_vocab_size=len(DE.vocab), dec_vocab_size=len(EN.vocab), \n",
    "              enc_embed_dim=1000, dec_embed_dim=1000, hidden_size=1000, \n",
    "              enc_num_layers=4, dec_num_layers=4)\n",
    "\n",
    "optimizer = optim.SGD(params=s2s.parameters(), lr=0.7)\n",
    "loss_func = nn.NLLLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.544413\n"
     ]
    }
   ],
   "source": [
    "trg_input = batch.trg[:-1]\n",
    "trg_output = batch.trg[1:]\n",
    "log_probs = s2s(batch.src, trg_input)\n",
    "loss = loss_func(log_probs.view(-1, len(EN.vocab)), trg_output.view(-1))\n",
    "print(loss.data.numpy()[0])\n",
    "#loss.backward()\n",
    "#optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type Variable[torch.LongTensor] but found type Variable[torch.ByteTensor] for argument #2 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-f0295ea21992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type Variable[torch.LongTensor] but found type Variable[torch.ByteTensor] for argument #2 'index'"
     ]
    }
   ],
   "source": [
    "log_probs.view(-1, len(EN.vocab)).gather(dim=0, index=Variable(pad_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or 4 dimensions (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-df540788c697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         return F.nll_loss(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 147\u001b[0;31m                           self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/py35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or 4 dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or 4 dimensions (got 3)"
     ]
    }
   ],
   "source": [
    "loss_func(log_probs, trg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0  ,.,.) = \n",
       " -9.3663 -9.4079 -9.3922  ...  -9.3665 -9.3700 -9.4017\n",
       " -9.3962 -9.3847 -9.3883  ...  -9.3876 -9.3993 -9.3922\n",
       " -9.3923 -9.3636 -9.3684  ...  -9.3778 -9.3797 -9.4046\n",
       "           ...             ⋱             ...          \n",
       " -9.3825 -9.4073 -9.3846  ...  -9.4410 -9.4001 -9.4076\n",
       " -9.3447 -9.3790 -9.4073  ...  -9.4271 -9.4367 -9.3828\n",
       " -9.4030 -9.3787 -9.3682  ...  -9.3813 -9.3810 -9.3948\n",
       "\n",
       "(  1  ,.,.) = \n",
       " -9.3695 -9.3911 -9.3999  ...  -9.3650 -9.3933 -9.3750\n",
       " -9.3867 -9.3951 -9.3867  ...  -9.3795 -9.4205 -9.3736\n",
       " -9.4123 -9.3689 -9.3652  ...  -9.3674 -9.3808 -9.3767\n",
       "           ...             ⋱             ...          \n",
       " -9.3727 -9.4051 -9.3952  ...  -9.4006 -9.4122 -9.3818\n",
       " -9.3394 -9.3859 -9.3884  ...  -9.4193 -9.4603 -9.3485\n",
       " -9.3991 -9.3729 -9.3645  ...  -9.3790 -9.4025 -9.3558\n",
       "\n",
       "(  2  ,.,.) = \n",
       " -9.3883 -9.3761 -9.3869  ...  -9.3706 -9.4057 -9.3441\n",
       " -9.3766 -9.4017 -9.3757  ...  -9.3776 -9.4232 -9.3633\n",
       " -9.4331 -9.3874 -9.3648  ...  -9.3599 -9.3788 -9.3451\n",
       "           ...             ⋱             ...          \n",
       " -9.3805 -9.3948 -9.3951  ...  -9.3858 -9.4225 -9.3671\n",
       " -9.3520 -9.4016 -9.3763  ...  -9.4118 -9.4891 -9.3291\n",
       " -9.4097 -9.3787 -9.3637  ...  -9.3674 -9.4112 -9.3292\n",
       " ...  \n",
       "\n",
       "(  9  ,.,.) = \n",
       " -9.4412 -9.3072 -9.3356  ...  -9.5216 -9.4638 -9.2807\n",
       " -9.4009 -9.3573 -9.3612  ...  -9.3422 -9.4108 -9.2809\n",
       " -9.4138 -9.3694 -9.3296  ...  -9.4470 -9.4466 -9.2805\n",
       "           ...             ⋱             ...          \n",
       " -9.4901 -9.2881 -9.3366  ...  -9.4134 -9.4865 -9.3385\n",
       " -9.4190 -9.2508 -9.3225  ...  -9.4389 -9.4627 -9.2342\n",
       " -9.4348 -9.3348 -9.3119  ...  -9.4703 -9.4418 -9.2575\n",
       "\n",
       "( 10  ,.,.) = \n",
       " -9.4534 -9.2806 -9.3317  ...  -9.5222 -9.4760 -9.2740\n",
       " -9.3980 -9.3566 -9.3578  ...  -9.3476 -9.4157 -9.2617\n",
       " -9.4093 -9.3407 -9.3342  ...  -9.4568 -9.4501 -9.2707\n",
       "           ...             ⋱             ...          \n",
       " -9.4856 -9.2696 -9.3413  ...  -9.4123 -9.4871 -9.3421\n",
       " -9.4329 -9.2330 -9.3085  ...  -9.4458 -9.4667 -9.2210\n",
       " -9.4460 -9.3230 -9.3242  ...  -9.4732 -9.4484 -9.2365\n",
       "\n",
       "( 11  ,.,.) = \n",
       " -9.4667 -9.2590 -9.3278  ...  -9.5204 -9.4812 -9.2715\n",
       " -9.4014 -9.3480 -9.3596  ...  -9.3518 -9.4177 -9.2448\n",
       " -9.4080 -9.3137 -9.3337  ...  -9.4683 -9.4476 -9.2602\n",
       "           ...             ⋱             ...          \n",
       " -9.4781 -9.2457 -9.3471  ...  -9.4143 -9.4812 -9.3415\n",
       " -9.4478 -9.2241 -9.2974  ...  -9.4542 -9.4689 -9.2141\n",
       " -9.4640 -9.3063 -9.3375  ...  -9.4750 -9.4482 -9.2157\n",
       "[torch.FloatTensor of size 12x32x11560]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.9086  0.8767  0.8406  ...   0.8312  0.8667  0.8676\n",
       "  0.8599  0.8723  0.8775  ...   0.8443  0.8595  0.8847\n",
       "  0.8765  0.8831  0.8667  ...   0.8624  0.8572  0.8702\n",
       "           ...             ⋱             ...          \n",
       "  0.8780  0.8896  0.9148  ...   0.8576  0.8404  0.8707\n",
       "  0.9144  0.8611  0.9002  ...   0.8774  0.8762  0.8810\n",
       "  0.8903  0.8734  0.8738  ...   0.8327  0.8584  0.8585\n",
       "\n",
       "(  1  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.9047  0.8695  0.8538  ...   0.8336  0.8776  0.8597\n",
       "  0.8576  0.8813  0.8825  ...   0.8583  0.8924  0.8739\n",
       "  0.8845  0.8861  0.8734  ...   0.8838  0.8615  0.8698\n",
       "           ...             ⋱             ...          \n",
       "  0.8826  0.8759  0.8980  ...   0.8677  0.8751  0.8571\n",
       "  0.9216  0.8464  0.8761  ...   0.8626  0.9146  0.8696\n",
       "  0.8961  0.8649  0.8738  ...   0.8600  0.8766  0.8507\n",
       "\n",
       "(  2  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8877  0.8683  0.8575  ...   0.8428  0.9021  0.8648\n",
       "  0.8582  0.8852  0.8840  ...   0.8611  0.9231  0.8668\n",
       "  0.8833  0.8871  0.8655  ...   0.8925  0.8644  0.8697\n",
       "           ...             ⋱             ...          \n",
       "  0.8852  0.8678  0.8795  ...   0.8606  0.9028  0.8537\n",
       "  0.9192  0.8294  0.8588  ...   0.8537  0.9465  0.8635\n",
       "  0.8978  0.8640  0.8633  ...   0.8828  0.8994  0.8512\n",
       " ...  \n",
       "\n",
       "(  9  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8851  0.8942  0.8495  ...   0.8472  0.9259  0.8984\n",
       "  0.9419  0.8745  0.9067  ...   0.7978  0.9518  0.8574\n",
       "  0.8890  0.8814  0.8951  ...   0.8183  0.9773  0.8352\n",
       "           ...             ⋱             ...          \n",
       "  0.8621  0.8654  0.8365  ...   0.7905  0.9504  0.8719\n",
       "  0.9003  0.9715  0.8213  ...   0.8743  0.9720  0.8764\n",
       "  0.9422  0.9562  0.8505  ...   0.8548  0.9175  0.8943\n",
       "\n",
       "( 10  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8822  0.9052  0.8322  ...   0.8500  0.9200  0.8899\n",
       "  0.9483  0.8630  0.9235  ...   0.7904  0.9433  0.8591\n",
       "  0.8838  0.8909  0.8782  ...   0.8208  0.9665  0.8307\n",
       "           ...             ⋱             ...          \n",
       "  0.8598  0.8817  0.8143  ...   0.7956  0.9381  0.8577\n",
       "  0.8914  0.9775  0.8056  ...   0.8638  0.9438  0.8652\n",
       "  0.9458  0.9813  0.8332  ...   0.8488  0.9058  0.8748\n",
       "\n",
       "( 11  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8774  0.9107  0.8142  ...   0.8528  0.9154  0.8835\n",
       "  0.9377  0.8584  0.9299  ...   0.7909  0.9361  0.8554\n",
       "  0.8754  0.8932  0.8562  ...   0.8242  0.9528  0.8300\n",
       "           ...             ⋱             ...          \n",
       "  0.8579  0.9078  0.7981  ...   0.7992  0.9211  0.8378\n",
       "  0.8825  0.9708  0.7933  ...   0.8588  0.9193  0.8566\n",
       "  0.9413  0.9985  0.8180  ...   0.8418  0.8913  0.8548\n",
       "[torch.FloatTensor of size 12x32x11560]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    probs = s2s(batch.src, batch.trg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.9086  0.8767  0.8406  ...   0.8312  0.8667  0.8676\n",
       "  0.8599  0.8723  0.8775  ...   0.8443  0.8595  0.8847\n",
       "  0.8765  0.8831  0.8667  ...   0.8624  0.8572  0.8702\n",
       "           ...             ⋱             ...          \n",
       "  0.8780  0.8896  0.9148  ...   0.8576  0.8404  0.8707\n",
       "  0.9144  0.8611  0.9002  ...   0.8774  0.8762  0.8810\n",
       "  0.8903  0.8734  0.8738  ...   0.8327  0.8584  0.8585\n",
       "\n",
       "(  1  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.9047  0.8695  0.8538  ...   0.8336  0.8776  0.8597\n",
       "  0.8576  0.8813  0.8825  ...   0.8583  0.8924  0.8739\n",
       "  0.8845  0.8861  0.8734  ...   0.8838  0.8615  0.8698\n",
       "           ...             ⋱             ...          \n",
       "  0.8826  0.8759  0.8980  ...   0.8677  0.8751  0.8571\n",
       "  0.9216  0.8464  0.8761  ...   0.8626  0.9146  0.8696\n",
       "  0.8961  0.8649  0.8738  ...   0.8600  0.8766  0.8507\n",
       "\n",
       "(  2  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8877  0.8683  0.8575  ...   0.8428  0.9021  0.8648\n",
       "  0.8582  0.8852  0.8840  ...   0.8611  0.9231  0.8668\n",
       "  0.8833  0.8871  0.8655  ...   0.8925  0.8644  0.8697\n",
       "           ...             ⋱             ...          \n",
       "  0.8852  0.8678  0.8795  ...   0.8606  0.9028  0.8537\n",
       "  0.9192  0.8294  0.8588  ...   0.8537  0.9465  0.8635\n",
       "  0.8978  0.8640  0.8633  ...   0.8828  0.8994  0.8512\n",
       " ...  \n",
       "\n",
       "(  9  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8851  0.8942  0.8495  ...   0.8472  0.9259  0.8984\n",
       "  0.9419  0.8745  0.9067  ...   0.7978  0.9518  0.8574\n",
       "  0.8890  0.8814  0.8951  ...   0.8183  0.9773  0.8352\n",
       "           ...             ⋱             ...          \n",
       "  0.8621  0.8654  0.8365  ...   0.7905  0.9504  0.8719\n",
       "  0.9003  0.9715  0.8213  ...   0.8743  0.9720  0.8764\n",
       "  0.9422  0.9562  0.8505  ...   0.8548  0.9175  0.8943\n",
       "\n",
       "( 10  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8822  0.9052  0.8322  ...   0.8500  0.9200  0.8899\n",
       "  0.9483  0.8630  0.9235  ...   0.7904  0.9433  0.8591\n",
       "  0.8838  0.8909  0.8782  ...   0.8208  0.9665  0.8307\n",
       "           ...             ⋱             ...          \n",
       "  0.8598  0.8817  0.8143  ...   0.7956  0.9381  0.8577\n",
       "  0.8914  0.9775  0.8056  ...   0.8638  0.9438  0.8652\n",
       "  0.9458  0.9813  0.8332  ...   0.8488  0.9058  0.8748\n",
       "\n",
       "( 11  ,.,.) = \n",
       "1.00000e-04 *\n",
       "  0.8774  0.9107  0.8142  ...   0.8528  0.9154  0.8835\n",
       "  0.9377  0.8584  0.9299  ...   0.7909  0.9361  0.8554\n",
       "  0.8754  0.8932  0.8562  ...   0.8242  0.9528  0.8300\n",
       "           ...             ⋱             ...          \n",
       "  0.8579  0.9078  0.7981  ...   0.7992  0.9211  0.8378\n",
       "  0.8825  0.9708  0.7933  ...   0.8588  0.9193  0.8566\n",
       "  0.9413  0.9985  0.8180  ...   0.8418  0.8913  0.8548\n",
       "[torch.FloatTensor of size 12x32x11560]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
