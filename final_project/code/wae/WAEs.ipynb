{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import spacy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en')\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, batch_first=True, tokenize=tokenize, init_token=BOS_WORD, eos_token=EOS_WORD)\n",
    "LABEL = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make splits for data\n",
    "train, val, test = datasets.SST.splits(TEXT, LABEL, '../../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f0c41d36080>, 'label': <torchtext.data.field.Field object at 0x7f0c41d36128>}\n",
      "len(train) 8544\n",
      "vars(train[0]) {'text': ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', \"'s\", 'new', '``', 'conan', \"''\", 'and', 'that', 'he', \"'s\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean', '-', 'claud', 'van', 'damme', 'or', 'steven', 'segal', '.'], 'label': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# print information about the data\n",
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 15483\n",
      "len(LABEL.vocab) 4\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('len(LABEL.vocab)', len(LABEL.vocab))\n",
    "\n",
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=32, \n",
    "                                                                       shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_IDX = TEXT.vocab.stoi[BOS_WORD]\n",
    "EOS_IDX = TEXT.vocab.stoi[EOS_WORD]\n",
    "PAD_IDX = TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, hidden_size, num_layers=1, dropout_frac=0.5):\n",
    "        \n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding.embedding_dim, hidden_size, num_layers)\n",
    "        self.dropout = nn.Dropout(p=dropout_frac)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        input = self.embedding(batch)\n",
    "        _, (hidden, _) = self.lstm(input.t())\n",
    "        hidden = self.dropout(hidden)\n",
    "        return hidden.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, hidden_size, num_layers=1, dropout_frac=0.5):\n",
    "        \n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding.embedding_dim + hidden_size, hidden_size, num_layers)\n",
    "        self.dropout = nn.Dropout(p=dropout_frac)\n",
    "        self.linear = nn.Linear(hidden_size, self.embedding.num_embeddings)\n",
    "        \n",
    "    def forward(self, batch, hidden_init):\n",
    "        seq_len = batch.size(1)\n",
    "        input = self.embedding(batch)\n",
    "        if USE_CUDA:\n",
    "            input = input.cuda()\n",
    "        hidden_init_repeated = torch.stack([hidden_init] * seq_len, 1)\n",
    "        input = torch.cat([input, hidden_init_repeated], dim=2)\n",
    "        cell_init = Variable(torch.zeros(hidden_init.size()))\n",
    "        if USE_CUDA:\n",
    "            cell_init = cell_init.cuda()\n",
    "        output, _ = self.lstm(input.t(), (hidden_init.unsqueeze(0), cell_init.unsqueeze(0)))\n",
    "        output = self.dropout(output)\n",
    "        output = output.t()\n",
    "        probs = F.softmax(self.linear(output), dim=2)\n",
    "        log_probs = torch.log(probs)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, latent_dim):\n",
    "        \n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.linear_mean = nn.Linear(encoder.hidden_size, self.latent_dim)\n",
    "        self.linear_var = nn.Linear(encoder.hidden_size, self.latent_dim)\n",
    "        self.linear_decoder = nn.Linear(self.latent_dim, decoder.hidden_size)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        batch_size = batch.size(0)\n",
    "        \n",
    "        # Take out BOS/EOS token for encoder and EOS token for decoder\n",
    "        batch_no_eos = batch.clone()\n",
    "        batch_no_eos[batch_no_eos == EOS_IDX] = 1\n",
    "        batch_no_eos = batch_no_eos[:, :-1]\n",
    "         \n",
    "        hidden = self.encoder(batch_no_eos[:, 1:])\n",
    "        means = self.linear_mean(hidden)\n",
    "        log_vars = self.linear_var(hidden)\n",
    "        Z = Variable(torch.normal(means=torch.zeros(batch_size, self.latent_dim), \n",
    "                                  std=torch.ones(batch_size, self.latent_dim)))\n",
    "        if USE_CUDA:\n",
    "            means = means.cuda()\n",
    "            log_vars = log_vars.cuda()\n",
    "            Z = Z.cuda()\n",
    "        latent = means + Z * torch.exp(1/2 * log_vars)\n",
    "        decoder_hidden_init = self.linear_decoder(latent)\n",
    "        log_probs = self.decoder(batch_no_eos, decoder_hidden_init)\n",
    "        return log_probs, means, log_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(target, log_probs, means, log_vars):\n",
    "    log_probs = torch.gather(log_probs, dim=2, index=target.unsqueeze(2)).squeeze()\n",
    "    pad_mask = target == PAD_IDX\n",
    "    n_tokens = (~pad_mask.data).long().sum()\n",
    "    log_probs[pad_mask] = 0\n",
    "    rec_loss = -log_probs.sum(dim=1)\n",
    "    reg_loss = -1/2 * torch.sum(1 + log_vars - means**2 - torch.exp(log_vars), dim=1)\n",
    "    batch_loss = rec_loss.sum() + reg_loss.sum()\n",
    "    return batch_loss, rec_loss.sum(), reg_loss.sum(), n_tokens\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    data_loss = 0\n",
    "    data_size = 0\n",
    "    total_reg_loss = 0\n",
    "    for batch in data:\n",
    "        model.zero_grad()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            batch.text = batch.text.cuda()\n",
    "        log_probs, means, log_vars = model(batch.text)\n",
    "        target = batch.text[:, 1:]\n",
    "        batch_loss, rec_loss, reg_loss, n_tokens = vae_loss(target, log_probs, means, log_vars)\n",
    "        \n",
    "        avg_loss = batch_loss / n_tokens\n",
    "        avg_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        data_size += n_tokens\n",
    "        data_loss += batch_loss\n",
    "        total_reg_loss += reg_loss\n",
    "    avg_loss_all = data_loss / data_size\n",
    "    avg_reg_loss_all = total_reg_loss / data_size\n",
    "    ppl = torch.exp(avg_loss_all)\n",
    "    return avg_loss_all, avg_reg_loss_all, ppl\n",
    "\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    data_loss = 0\n",
    "    data_size = 0\n",
    "    total_reg_loss = 0\n",
    "    for batch in data:        \n",
    "        if USE_CUDA:\n",
    "            batch.text = batch.text.cuda()\n",
    "        log_probs, means, log_vars = model(batch.text)\n",
    "        target = batch.text[:, 1:]\n",
    "        batch_loss, rec_loss, reg_loss, n_tokens = vae_loss(target, log_probs, means, log_vars)\n",
    "                \n",
    "        data_size += n_tokens\n",
    "        data_loss += batch_loss\n",
    "        total_reg_loss += reg_loss\n",
    "    avg_loss_all = data_loss / data_size\n",
    "    avg_reg_loss_all = total_reg_loss / data_size\n",
    "    ppl = torch.exp(avg_loss_all)\n",
    "    model.train()\n",
    "    return avg_loss_all, avg_reg_loss_all, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=256)\n",
    "encoder = LSTMEncoder(embedding, hidden_size=256)\n",
    "decoder = LSTMDecoder(embedding, hidden_size=256)\n",
    "vae = VAE(encoder, decoder, latent_dim=64)\n",
    "if USE_CUDA:\n",
    "    vae = vae.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch # 0 | time 33.61 | train loss  6.61 | train ppl 744.20 | test loss  6.15 | test reg  0.00 | test ppl 469.82\n",
      "| Epoch # 1 | time 32.53 | train loss  5.92 | train ppl 371.89 | test loss  5.94 | test reg  0.00 | test ppl 380.69\n",
      "| Epoch # 2 | time 33.67 | train loss  5.62 | train ppl 275.44 | test loss  5.83 | test reg  0.00 | test ppl 340.56\n",
      "| Epoch # 3 | time 33.55 | train loss  5.37 | train ppl 214.85 | test loss  5.79 | test reg  0.00 | test ppl 325.86\n",
      "| Epoch # 4 | time 33.30 | train loss  5.15 | train ppl 172.02 | test loss  5.76 | test reg  0.00 | test ppl 318.30\n",
      "| Epoch # 5 | time 33.28 | train loss  4.94 | train ppl 139.38 | test loss  5.73 | test reg  0.00 | test ppl 308.48\n",
      "| Epoch # 6 | time 33.08 | train loss  4.73 | train ppl 113.34 | test loss  5.75 | test reg  0.00 | test ppl 313.73\n",
      "| Epoch # 7 | time 35.21 | train loss  4.53 | train ppl 92.89 | test loss  5.75 | test reg  0.00 | test ppl 315.21\n",
      "| Epoch # 8 | time 38.41 | train loss  4.34 | train ppl 76.96 | test loss  5.79 | test reg  0.00 | test ppl 327.43\n",
      "| Epoch # 9 | time 37.64 | train loss  4.16 | train ppl 64.01 | test loss  5.84 | test reg  0.00 | test ppl 343.48\n",
      "| Epoch #10 | time 37.28 | train loss  3.99 | train ppl 53.83 | test loss  5.84 | test reg  0.00 | test ppl 345.45\n",
      "| Epoch #11 | time 36.88 | train loss  3.82 | train ppl 45.75 | test loss  5.88 | test reg  0.00 | test ppl 358.90\n",
      "| Epoch #12 | time 37.25 | train loss  3.67 | train ppl 39.37 | test loss  5.93 | test reg  0.00 | test ppl 375.27\n",
      "| Epoch #13 | time 37.15 | train loss  3.53 | train ppl 34.20 | test loss  5.97 | test reg  0.00 | test ppl 390.59\n",
      "| Epoch #14 | time 37.93 | train loss  3.40 | train ppl 29.89 | test loss  6.03 | test reg  0.00 | test ppl 414.67\n",
      "| Epoch #15 | time 37.11 | train loss  3.27 | train ppl 26.37 | test loss  6.08 | test reg  0.00 | test ppl 435.76\n",
      "| Epoch #16 | time 36.51 | train loss  3.15 | train ppl 23.40 | test loss  6.12 | test reg  0.00 | test ppl 454.63\n",
      "| Epoch #17 | time 36.56 | train loss  3.05 | train ppl 21.03 | test loss  6.18 | test reg  0.00 | test ppl 485.25\n",
      "| Epoch #18 | time 33.13 | train loss  2.94 | train ppl 18.89 | test loss  6.22 | test reg  0.00 | test ppl 504.38\n",
      "| Epoch #19 | time 33.89 | train loss  2.84 | train ppl 17.09 | test loss  6.27 | test reg  0.00 | test ppl 525.94\n",
      "| Epoch #20 | time 33.42 | train loss  2.74 | train ppl 15.55 | test loss  6.32 | test reg  0.00 | test ppl 555.90\n",
      "| Epoch #21 | time 33.29 | train loss  2.66 | train ppl 14.32 | test loss  6.39 | test reg  0.00 | test ppl 597.82\n",
      "| Epoch #22 | time 33.34 | train loss  2.58 | train ppl 13.17 | test loss  6.46 | test reg  0.00 | test ppl 639.10\n",
      "| Epoch #23 | time 33.17 | train loss  2.50 | train ppl 12.21 | test loss  6.48 | test reg  0.00 | test ppl 654.26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-57c972047bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e70420b3c1f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e70420b3c1f7>\u001b[0m in \u001b[0;36mvae_loss\u001b[0;34m(target, log_probs, means, log_vars)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for i in range(30):\n",
    "    t = time.time()\n",
    "    train_loss, _, train_ppl = train(vae, train_iter, optimizer)\n",
    "    train_time = time.time() - t\n",
    "    test_loss, reg_loss, test_ppl = evaluate(vae, test_iter)\n",
    "    \n",
    "    train_loss = train_loss.data[0]\n",
    "    train_ppl = train_ppl.data[0]\n",
    "    test_loss = test_loss.data[0]\n",
    "    reg_loss = reg_loss.data[0]\n",
    "    test_ppl = test_ppl.data[0]\n",
    "    \n",
    "    print('| Epoch #{:2d} | time {:4.2f} | train loss {:5.2f} | train ppl {:5.2f} | test loss {:5.2f} | test reg {:5.2f} | test ppl {:5.2f}'.format(i, train_time, train_loss, train_ppl, test_loss, reg_loss, test_ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, k=3, in_channels=512 + 256, mid_channels=512, out_channels=512 + 256):\n",
    "        \n",
    "        super(ResidualBlock, self).__init__()\n",
    "    \n",
    "        self.in_channels = in_channels\n",
    "        self.mid_channels = mid_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.d = d\n",
    "        self.k = k\n",
    "        self.n_pad = n_pad = k * d - d\n",
    "        \n",
    "        self.conv1x1_A = torch.nn.Conv1d(in_channels, mid_channels, kernel_size=1)\n",
    "        self.convkx1 = torch.nn.Conv1d(mid_channels, mid_channels, kernel_size=k, dilation=d, padding=n_pad)\n",
    "        self.conv1x1_B = torch.nn.Conv1d(mid_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = F.relu(input)\n",
    "        out = self.conv1x1_A(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.convkx1(out)[:, :, :-self.n_pad]\n",
    "        out = F.relu(out)\n",
    "        out = self.conv1x1_B(out)\n",
    "        out = out + input\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilatedCNNDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding, hidden_size, dilation_layers=[1, 2, 4], filter_size=3):\n",
    "        \n",
    "        super(DilatedCNNDecoder, self).__init__()\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dilation_layers = dilation_layers\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "        resid_blocks = []\n",
    "        for d in dilation_layers:\n",
    "            resid_blocks.append(ResidualBlock(d, k=filter_size))\n",
    "        self.resid_blocks = nn.ModuleList(resid_blocks)\n",
    "        self.linear = nn.Linear(resid_blocks[-1].out_channels, embedding.num_embeddings)\n",
    "        \n",
    "    def forward(self, batch, hidden_init):\n",
    "        seq_len = batch.size(1)\n",
    "        input = self.embedding(batch)\n",
    "        if USE_CUDA:\n",
    "            input = input.cuda()\n",
    "        hidden_init_repeated = torch.stack([hidden_init] * seq_len, 1)\n",
    "        out = torch.cat([input, hidden_init_repeated], dim=2)\n",
    "        out = out.transpose(1, 2)\n",
    "        \n",
    "        for r_block in self.resid_blocks:\n",
    "            out = r_block(out)\n",
    "        out = out.transpose(1, 2)\n",
    "        probs = F.softmax(self.linear(out), dim=2)\n",
    "        log_probs = torch.log(probs)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2 = nn.Embedding(num_embeddings=len(TEXT.vocab), embedding_dim=256)\n",
    "encoder2 = LSTMEncoder(embedding2, hidden_size=512)\n",
    "decoder2 = DilatedCNNDecoder(embedding2, hidden_size=512)\n",
    "vae_dilated = VAE(encoder2, decoder2, latent_dim=32)\n",
    "if USE_CUDA:\n",
    "    vae_dilated = vae_dilated.cuda()\n",
    "    \n",
    "optimizer2 = optim.Adam(vae_dilated.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch # 0 | time 50.04 | train loss  6.39 | train ppl 594.97 | test loss  6.04 | test reg  0.00 | test ppl 420.01\n",
      "| Epoch # 1 | time 51.38 | train loss  5.49 | train ppl 241.71 | test loss  5.94 | test reg  0.00 | test ppl 379.97\n",
      "| Epoch # 2 | time 52.03 | train loss  5.00 | train ppl 148.71 | test loss  5.87 | test reg  0.00 | test ppl 355.22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-6a6767030b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_dilated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_dilated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e70420b3c1f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e70420b3c1f7>\u001b[0m in \u001b[0;36mvae_loss\u001b[0;34m(target, log_probs, means, log_vars)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrec_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_vars\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Train model\n",
    "for i in range(30):\n",
    "    t = time.time()\n",
    "    train_loss, _, train_ppl = train(vae_dilated, train_iter, optimizer2)\n",
    "    train_time = time.time() - t\n",
    "    test_loss, reg_loss, test_ppl = evaluate(vae_dilated, test_iter)\n",
    "    \n",
    "    train_loss = train_loss.data[0]\n",
    "    train_ppl = train_ppl.data[0]\n",
    "    test_loss = test_loss.data[0]\n",
    "    reg_loss = reg_loss.data[0]\n",
    "    test_ppl = test_ppl.data[0]\n",
    "    \n",
    "    print('| Epoch #{:2d} | time {:4.2f} | train loss {:5.2f} | train ppl {:5.2f} | test loss {:5.2f} | test reg {:5.2f} | test ppl {:5.2f}'.format(i, train_time, train_loss, train_ppl, test_loss, reg_loss, test_ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(  0  ,.,.) = \n",
       " -10.3526  -9.3471  -9.6030  ...  -10.1425  -9.4990  -9.5840\n",
       " -10.1305  -9.6689 -10.1028  ...  -10.2751  -9.4249  -9.9911\n",
       " -10.2381  -9.6977 -10.3961  ...   -9.6479  -9.6753  -9.1942\n",
       "            ...               ⋱              ...            \n",
       " -10.2831  -9.1699 -10.9693  ...   -9.8108  -9.6649  -9.7658\n",
       "  -9.9476  -9.0176  -9.9333  ...  -10.5735  -9.3686  -9.1843\n",
       " -10.2049  -8.5085  -9.5729  ...   -9.7321  -9.6015 -10.2293\n",
       "\n",
       "(  1  ,.,.) = \n",
       " -10.0810 -10.0030  -9.4868  ...  -10.1834  -9.5610  -9.2903\n",
       "  -9.9780  -9.6010  -9.6552  ...  -10.4450  -9.1934  -9.4402\n",
       "  -9.2953  -9.8903 -10.0582  ...   -9.9064  -9.3533  -9.3996\n",
       "            ...               ⋱              ...            \n",
       " -10.3158  -9.1531 -10.1516  ...   -9.7145  -9.1483  -9.7620\n",
       "  -9.6362  -9.6684  -9.7638  ...  -10.5614  -9.4083  -9.0233\n",
       "  -9.8283  -9.1205  -9.5133  ...   -9.8005  -9.6368 -10.1266\n",
       "\n",
       "(  2  ,.,.) = \n",
       " -10.1020  -9.8092  -9.1300  ...  -10.0079  -9.7844  -9.7142\n",
       "  -8.9096  -9.4558  -9.9791  ...  -10.7629  -9.3811 -10.0993\n",
       "  -9.6348  -9.4610  -9.5939  ...  -10.1640  -9.3324  -9.5381\n",
       "            ...               ⋱              ...            \n",
       " -10.5142 -10.2169  -8.7965  ...   -9.8494 -10.6796  -9.5203\n",
       "  -9.8279  -9.6145  -9.5538  ...  -10.4118  -9.5830  -9.3503\n",
       "  -9.9111  -9.0638  -9.1263  ...   -9.6298  -9.9090 -10.3800\n",
       " ...  \n",
       "\n",
       "( 29  ,.,.) = \n",
       " -10.3222 -10.0024  -9.7126  ...   -9.9148  -9.7056 -10.0609\n",
       "  -9.7120  -9.3106 -10.8765  ...   -9.8096  -9.9086 -10.2708\n",
       "  -9.8086  -9.3320  -9.6741  ...   -9.8831 -10.0949 -10.0168\n",
       "            ...               ⋱              ...            \n",
       "  -9.2063  -9.7170 -10.5666  ...  -10.6747  -9.2333 -10.4787\n",
       "  -9.7983  -9.8523  -9.5917  ...  -10.0387  -9.8293 -10.3001\n",
       "  -9.9194  -9.7502  -9.9776  ...  -10.2498  -9.5073  -9.8134\n",
       "\n",
       "( 30  ,.,.) = \n",
       " -10.1754 -10.0274  -9.5011  ...  -10.1359  -9.6856  -9.8687\n",
       "  -8.9642  -9.6982 -10.3630  ...  -10.9093  -9.2901 -10.2559\n",
       " -10.1350  -9.9692  -9.3526  ...   -9.5856  -9.9864  -8.6824\n",
       "            ...               ⋱              ...            \n",
       "  -8.9783  -9.7033 -10.3482  ...  -10.8425  -9.2667 -10.2534\n",
       " -10.3431  -9.2830 -10.1663  ...  -10.0230  -9.8196  -9.7711\n",
       "  -9.7529  -9.8126  -9.8305  ...  -10.5207  -9.5101  -9.5644\n",
       "\n",
       "( 31  ,.,.) = \n",
       " -10.2994 -10.1110  -9.4225  ...   -9.5486  -9.9338  -9.6012\n",
       "  -9.5642  -9.2018  -9.6820  ...   -9.5980 -10.3666 -10.0725\n",
       " -10.5657  -9.3691  -9.2684  ...   -9.2574  -9.5150  -9.5343\n",
       "            ...               ⋱              ...            \n",
       "  -9.3673  -9.6483  -9.7676  ...   -9.3430 -10.7003 -10.1409\n",
       "  -9.8800  -9.8757  -9.6967  ...   -9.8240  -9.7645  -9.7560\n",
       "  -9.9122  -9.8352  -9.7227  ...   -9.9801  -9.8133  -9.1170\n",
       "[torch.cuda.FloatTensor of size 32x12x15483 (GPU 0)]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder2(batch_no_eos, hidden_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
