\documentclass[11pt, margin=1in]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{hyperref}

\hypersetup{
    colorlinks=true,
    citecolor=blue,
    urlcolor=red
}

% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{fact}[theorem]{Fact}
\usepackage{tikz}
\usetikzlibrary{arrows}
\newenvironment{proof}{\noindent {\it Proof.}}{\hfill\rule{2mm}{2mm}}
\pagestyle{fancy}
\lhead{\textbf{CS287r Project Proposal}}
\rhead{\textit{Alex Lin \& Melissa Yu}}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\newcommand{\card}[1]{\ensuremath{\left\vert#1\right\vert}}
\newcommand{\diff}[1]{\, d#1}
\newcommand{\eval}[2]{\Big|_{#1}^{#2}}

\makeatletter

\begin{document}
	
\title{CS287r Project Proposal \\ WAEs for Natural Language Modeling}
\author{Alex Lin (alexanderlin01@college.harvard.edu) \and Melissa Yu (melissayu@college.harvard.edu)}
\date{}
\maketitle

We're utilizing the recently proposed Wasserstein Auto-Encoders (WAE), which has been shown to work well for image generation (generating samples with better FID scores) while sharing many of the properties of VAEs, to the problem of language modeling. The WAE model can be understood to be a generalization of Adversarial Auto-Encoders (AAE).

\section{Details}
\subsection{Papers}
\begin{enumerate}
	\item \textbf{Major paper}: Wasserstein Auto-Encoders. Tolstikhin et al.
	\item Generating Sentences from a Continuous Space. Bowman et al.
	\item Toward Controlled Generation of Text. Hu et al.
	\item Improved Variational Autoencoders for Text Modeling using Dilated Convolutions. Yang et al.
\end{enumerate}

\subsection{Time}
We are presenting on April 5.

\subsection{Baseline} 
Baselines for language modeling come from these models (in the supporting papers specified above):
\begin{enumerate}
	\item LSTM-VAE
	\item RNNLM
	\item LCNN-VAE
\end{enumerate}

\end{document}