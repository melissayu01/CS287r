{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: PyTorch Tutorial (Tensors, Automatic Differentation, Linear Regression, MNIST Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Goal\n",
    "\n",
    "1. Learn to work with/manipulate tensors in PyTorch\n",
    "2. Learn about automatic differentiation\n",
    "3. Fit a linear regression model\n",
    "3. Build a simple classifier on MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors, or multidimensional arrays, are fundamental objects that you will be working with in Torch (and deep learning in general). Let's create some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-5.7846  0.0000 -5.7846  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 1.3962e+14  1.3962e+14\n",
      " 1.0000e+00  3.7332e+11\n",
      " 0.0000e+00  4.2950e+09\n",
      " 0.0000e+00  3.3000e+01\n",
      " 3.7331e+11  1.3962e+14\n",
      "[torch.LongTensor of size 5x2]\n",
      "\n",
      "\n",
      " 136\n",
      "[torch.ByteTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5,5) #create a 5 x 5 tensor\n",
    "print(x)\n",
    "x = torch.LongTensor(5,2) #often our input data consists of integers (word indices), so it's helpful to use LongTensors\n",
    "print(x)\n",
    "x = torch.ByteTensor(1,1)\n",
    "print(x)\n",
    "#we can also do other initializations\n",
    "x = torch.randn(3,4) #initialize from standard normal\n",
    "x = torch.ones(3,4) #all ones\n",
    "x = torch.zeros(3,4) #all zeros\n",
    "x = torch.eye(3) # identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go back between numpy/torch tensors with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42960673  1.50988904  0.69349265  1.23092394 -2.54778714]\n",
      "\n",
      " 0.4296\n",
      " 1.5099\n",
      " 0.6935\n",
      " 1.2309\n",
      "-2.5478\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n",
      "[ 0.          1.50988904  0.69349265  1.23092394 -2.54778714]\n"
     ]
    }
   ],
   "source": [
    "x_numpy = np.random.randn(5)\n",
    "print(x_numpy)\n",
    "x_torch = torch.from_numpy(x_numpy)\n",
    "print(x_torch)\n",
    "x_torch[0] = 0\n",
    "print(x_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing torch tensors is essentially identitical to the case in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2424112558364868\n",
      "\n",
      "-1.2424\n",
      " 1.0344\n",
      "-0.6358\n",
      " 0.4173\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "\n",
      "-1.2424 -1.0825 -2.4514\n",
      "-0.6358  0.7898  0.4812\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 100.0000  100.0000  100.0000\n",
      "   1.0344   -1.5117   -0.6687\n",
      " 100.0000  100.0000  100.0000\n",
      "   0.4173   -0.2641    1.2155\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,3)\n",
    "print(x[0, 0]) \n",
    "print(x[:, 0]) \n",
    "print(x[[0,2], :])\n",
    "x[[0,2], :] = 100\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to manipulate tensors. Of particular utility is the *view* function, which reshapes a tensor in memory. See [here](http://pytorch.org/docs/master/tensors.html) for more operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0687  0.6584 -0.8776 -0.0458 -1.8898  0.9141\n",
      " 2.8086 -1.5170 -0.7729  0.4793 -1.0196  0.5272\n",
      "[torch.FloatTensor of size 2x6]\n",
      "\n",
      "\n",
      " 1.0687\n",
      " 0.6584\n",
      "-0.8776\n",
      "-0.0458\n",
      "-1.8898\n",
      " 0.9141\n",
      " 2.8086\n",
      "-1.5170\n",
      "-0.7729\n",
      " 0.4793\n",
      "-1.0196\n",
      " 0.5272\n",
      "[torch.FloatTensor of size 12]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.6459 -0.1662 -0.1612  0.8961 -0.3470\n",
       " 0.9678  0.1589 -1.7035  0.4087  0.5826\n",
       "-1.5407  0.2940 -0.7082 -1.1668 -0.0078\n",
       " 0.6252 -1.2950  0.6264  0.7838 -0.3938\n",
       " 2.4792 -1.7871 -0.9470  1.6338  0.0845\n",
       "-2.3959 -0.0946 -0.9082 -0.1912  1.1389\n",
       "-0.8046 -0.7894 -0.9371  0.1127  1.5833\n",
       "-1.7731 -1.4199  0.1563  0.6043  0.3891\n",
       " 0.1100  1.8553  1.6423 -0.3854 -0.9171\n",
       " 1.1319 -1.1795 -1.5360  0.2060 -1.0844\n",
       "-0.6217 -0.9680 -1.8815 -0.8383 -0.2641\n",
       " 0.7409 -0.8969 -0.6261 -1.2428 -0.8121\n",
       "[torch.FloatTensor of size 12x5]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(12)\n",
    "print(x.view(2,6)) #reshape the 4x3 tensor into a 2x6 tensor\n",
    "print(x.view(-1)) # -1 always reshapes to a 1d tensor\n",
    "\n",
    "x = torch.randn(3,4,5)\n",
    "x.view(12, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use operations on tensors as in numpy. Operations that have an underscore _ are *in-place* and modify the original tensor. Other operations will create a new tensor in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.5994 -0.2923  1.2099  0.0675 -0.5873\n",
      " 0.0973  1.3780  1.6060  1.1143  1.9891\n",
      " 1.9164  0.1174  0.0359 -0.6382  1.0067\n",
      " 0.7691  0.4132 -0.2730  0.3485 -0.0722\n",
      "-1.3032  1.4591  0.9668  0.8160 -0.3060\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      "-0.5994 -0.2923  1.2099  0.0675 -0.5873\n",
      " 0.0973  1.3780  1.6060  1.1143  1.9891\n",
      " 1.9164  0.1174  0.0359 -0.6382  1.0067\n",
      " 0.7691  0.4132 -0.2730  0.3485 -0.0722\n",
      "-1.3032  1.4591  0.9668  0.8160 -0.3060\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      "-0.1464 -0.7828  1.5252  0.6232 -0.8830\n",
      "-0.5210 -0.3740  2.3736  1.2032  1.3623\n",
      " 3.2040 -0.9582 -1.0819 -0.2666  0.8687\n",
      " 0.6533 -0.5783 -1.6463  0.2718 -0.4932\n",
      "-1.5652  2.4988  0.1165  0.0668 -1.9983\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 5)\n",
    "y = torch.randn(5, 5)\n",
    "z = torch.mm(x, y) #matrix multiply\n",
    "z = 2*x # scalar multiplication\n",
    "z = x + y #addition, creates a new tensor\n",
    "print(x)\n",
    "z = x.add(y) #same\n",
    "print(x)\n",
    "x.add_(y) #modifies x by adding y to it\n",
    "print(x)\n",
    "#there are other operations such as x.mul_(), x.div_() etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so the tensor object is basically the same as a numpy array. What's neat is that you can define **computation graphs** with tensors and backpropagate gradients through this computational graph automatically. This is known as automatic differentation. To do this however, we need to use a `Variable` object which is basically a wrapper around a tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2476\n",
      " 1.9059\n",
      "-0.7489\n",
      " 0.9712\n",
      " 1.0852\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.randn(5), requires_grad=True) #requires grad means that we want to calculate gradients\n",
    "print(x.data) #a tensor object\n",
    "print(x.grad) #the gradient. right now we haven't calculated any gradients so there is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.8822\n",
      " 2.7576\n",
      " 2.7958\n",
      " 1.4661\n",
      "-2.6445\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(5), requires_grad=True) \n",
    "y = x.mul(2) #y is now a variable. almost any operation you can do on tensors you can do on Variables\n",
    "print(y)\n",
    "y.backward(Variable(torch.ones(y.size()))) #this is a tricky concept, but we essentially backprop a vector of ones\n",
    "#to simulate the calculation of dy[i] / dx for all i\n",
    "print(x.grad) #this should be a vector of 2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in practice, we almost always calculate the derivatve with respect to a **scalar**. In this case we can simply call `.backward()` without having to backpropagate a 1x1 vector of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 6\n",
      " 6\n",
      " 6\n",
      " 6\n",
      " 6\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "Variable containing:\n",
      " 0.1798\n",
      " 0.0978\n",
      " 1.1039\n",
      "-0.6699\n",
      " 1.0253\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#x = Variable(torch.randn(5), requires_grad=True)\n",
    " #gradients are always accumulated, so we need to zero them out manually\n",
    "y = x.mul(2).sum() # now y is a scalar. In most cases this would be your average loss\n",
    "y.backward() #this is equivalent to y.backward(Variable(torch.ones(y.size())))\n",
    "print(x.grad)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a simple least squares model on a synthetic dataset with gradient descent. First let's generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_points = 1000\n",
    "num_features = 5\n",
    "w_star = torch.randn(num_features) #true weight vector\n",
    "x = torch.randn(num_points, num_features) #input data\n",
    "y = torch.mm(x, w_star.view(5, 1)) #torch.mm expects both inputs to be matrices so we cast w_star to be a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem has an analytic solution which we can calculate directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.5207\n",
      "-0.0331\n",
      " 0.2725\n",
      "-0.9453\n",
      " 1.2381\n",
      "[torch.FloatTensor of size 5x1]\n",
      "\n",
      "\n",
      " 1.5207\n",
      "-0.0331\n",
      " 0.2725\n",
      "-0.9453\n",
      " 1.2381\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_ols = torch.mm(torch.mm(torch.inverse(torch.mm(x.t(), x)), x.t()), y) #(X^T X)^{-1} X^T Y\n",
    "print(w_ols)\n",
    "print(w_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's see if we can obtain (approximately) the same solution with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15.81375503540039\n",
      "10 0.18027447164058685\n",
      "20 0.002335350727662444\n",
      "30 3.43216561304871e-05\n",
      "40 5.65595200896496e-07\n",
      "Variable containing:\n",
      " 1.5206\n",
      "-0.0331\n",
      " 0.2725\n",
      "-0.9453\n",
      " 1.2381\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "\n",
      " 1.5207\n",
      "-0.0331\n",
      " 0.2725\n",
      "-0.9453\n",
      " 1.2381\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_sgd = Variable(torch.randn(num_features), requires_grad=True) #randomly initialize\n",
    "x_sgd = Variable(x) #remember, we need to convert everything to Variables to work with automatic differentiation\n",
    "y_sgd = Variable(y) #we don't need to calculate gradients with respect to these guys\n",
    "\n",
    "num_iters = 50\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(num_iters):\n",
    "    if w_sgd.grad is not None:\n",
    "        w_sgd.grad.zero_() #gradients get accumulated so we have to manually zero them out\n",
    "    y_pred = torch.mm(x_sgd, w_sgd.unsqueeze(1)) #unsqueeze adds an extra dimension\n",
    "    error = (y_sgd - y_pred)**2\n",
    "    error_avg = error.mean()\n",
    "    if i % 10 == 0:\n",
    "        print(i, error_avg.data[0])\n",
    "    error_avg.backward()    \n",
    "    w_sgd.data = w_sgd.data - learning_rate*w_sgd.grad.data\n",
    "        \n",
    "print(w_sgd)\n",
    "print(w_star)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that worked, but it's a bit annoying to separately define the weights as `Variables` and manually apply matrix-multiplies. Fortunately, torch provides an `nn` package which provides abstractions for almost all of the layers that we will use in the course. Let's see a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 0.1456  0.3603  0.2571 -0.2601 -0.1434\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n",
      "Parameter containing:\n",
      " 0.1307\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1.0946\n",
      "-0.0716\n",
      "-1.1583\n",
      "   ⋮    \n",
      "-0.8441\n",
      " 0.6244\n",
      "-0.0349\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n",
      "Variable containing:\n",
      " 1.0946\n",
      "-0.0716\n",
      "-1.1583\n",
      "   ⋮    \n",
      "-0.8441\n",
      " 0.6244\n",
      "-0.0349\n",
      "[torch.FloatTensor of size 1000x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "lin = nn.Linear(num_features, 1, bias=True) #this defines a linear layer that goes from num_feature dimensions to 1\n",
    "print(lin.weight) #weight parameter of the linear layer. if bias = True, then we can access bias with lin.bias\n",
    "print(lin.bias)\n",
    "y_pred = lin(x_sgd) #lin(x_sgd) automatically calls forward on the input x_sgd\n",
    "print(y_pred)\n",
    "print(lin.forward(x_sgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of `nn` layers can be found [here](http://pytorch.org/docs/master/nn.html). You should try to familiarize yourself with pretty much all the `nn` layers. Torch also provides an `optim` package that makes parameter updates easier. We will be working with SGD in this tutorial, but other optimization algorithms (Adam, Adagrad, RMSProp, etc) can be found [here](http://pytorch.org/docs/master/optim.html). Let's try to fit the linear regression model with these abstractions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 1.5206 -0.0331  0.2725 -0.9453  1.2381\n",
      "[torch.FloatTensor of size 1x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(lin.parameters(), lr = learning_rate) #initialize with parameters\n",
    "for i in range(num_iters):\n",
    "    optimizer.zero_grad() #this will zero out the gradients of all your parameters\n",
    "    y_pred = lin(x_sgd)\n",
    "    error = (y_sgd - y_pred)**2\n",
    "    error_avg = error.mean()    \n",
    "    error_avg.backward()    \n",
    "    optimizer.step()    \n",
    "print(lin.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#conda install torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "val_dataset = datasets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch provides a loader around tensor datasets so you can create/access mini-batches easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "for (image, label) in train_loader: #iterates through the dataset in mini-batches\n",
    "    print(image.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we are ready to create our first model, which will be a simple multilayer perceptron. To do this, it helps to define a `class` with all the layers inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_to_output): Linear(in_features=10, out_features=10)\n",
      "  (hidden_layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (logsoftmax): LogSoftmax()\n",
      ")\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10])\n",
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_layers = 1, input_dim = 28*28, \n",
    "                 output_dim = 10, hidden_dim = 10):\n",
    "        super(MLP, self).__init__()                \n",
    "        self.hidden_to_output = nn.Linear(hidden_dim, output_dim)\n",
    "        hidden_layers = []\n",
    "        for l in range(num_layers):\n",
    "            dim = input_dim if l == 0 else hidden_dim #first layer is input to hidden layer\n",
    "            hidden_layers.append(nn.Linear(dim, hidden_dim))\n",
    "            hidden_layers.append(nn.ReLU()) #let's work with relu nonlinearities for now\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers) #Sequential module will apply the layers in sequence\n",
    "        self.logsoftmax = nn.LogSoftmax() #softmax will turn the output into probabilities, but log is more convnient\n",
    "        \n",
    "    def forward(self, x): #MLP(x) is shorthand for MLP.forward(x)\n",
    "        x_flatten = x.view(x.size(0), 28*28) #need to flatten batch_size x 1 x 28 x 28 to batch_size x 28*28\n",
    "        out = self.hidden_layers(x_flatten)\n",
    "        out = self.hidden_to_output(out) #you can redefine variables\n",
    "        return self.logsoftmax(out)\n",
    "        \n",
    "mlp = MLP(num_layers = 1)\n",
    "print(mlp)\n",
    "for p in mlp.parameters(): #all the parameters that were defined inside the module can be accessed like this\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the network is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-2.2134 -2.5517 -2.4334  ...  -2.0741 -2.5961 -2.3051\n",
      "-2.1313 -2.5291 -2.4315  ...  -2.1081 -2.5845 -2.2901\n",
      "-2.2552 -2.5871 -2.3916  ...  -2.1364 -2.4609 -2.4157\n",
      "          ...             ⋱             ...          \n",
      "-2.1082 -2.5726 -2.4199  ...  -2.1017 -2.6651 -2.3162\n",
      "-2.2398 -2.4848 -2.4240  ...  -2.1305 -2.5736 -2.3076\n",
      "-2.1989 -2.5101 -2.3996  ...  -2.0990 -2.5569 -2.3216\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "Variable containing:\n",
      " 0.1093\n",
      " 0.0780\n",
      " 0.0877\n",
      " 0.0780\n",
      " 0.1283\n",
      " 0.0873\n",
      " 0.1315\n",
      " 0.1257\n",
      " 0.0746\n",
      " 0.0997\n",
      "[torch.FloatTensor of size 10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonkim/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp(Variable(image))\n",
    "print(y_pred) #these will be log probabilities over each of the 10 classes\n",
    "print(y_pred[0].exp()) #let's make sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also convenient to define a test function that we can call periodically to check performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonkim/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance. NLL: 0.3026, Accuracy: 0.9113\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss() #this is the negative log-likelihood for multi-class classification\n",
    "\n",
    "def test(model, data):\n",
    "    correct = 0.\n",
    "    num_examples = 0.\n",
    "    nll = 0.\n",
    "    for (image, label) in data:\n",
    "        image, label = Variable(image), Variable(label) #annoying, but necessary        \n",
    "        y_pred = mlp(image)\n",
    "        nll_batch = criterion(y_pred, label)\n",
    "        nll += nll_batch.data[0] * image.size(0) #by default NLL is averaged over each batch\n",
    "        y_pred_max, y_pred_argmax = torch.max(y_pred, 1) #prediction is the argmax\n",
    "        correct += (y_pred_argmax.data == label.data).sum() \n",
    "        num_examples += image.size(0) \n",
    "    return nll/num_examples, correct/num_examples\n",
    "nll, accuracy = test(mlp, val_loader)\n",
    "print('Validation performance. NLL: %.4f, Accuracy: %.4f'% (nll, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonkim/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance after epoch 1: NLL: 0.2917, Accuracy: 0.9130\n",
      "Validation performance after epoch 1: NLL: 0.2904, Accuracy: 0.9154\n",
      "Training performance after epoch 2: NLL: 0.2638, Accuracy: 0.9235\n",
      "Validation performance after epoch 2: NLL: 0.2710, Accuracy: 0.9230\n",
      "Training performance after epoch 3: NLL: 0.2402, Accuracy: 0.9292\n",
      "Validation performance after epoch 3: NLL: 0.2436, Accuracy: 0.9272\n",
      "Training performance after epoch 4: NLL: 0.2436, Accuracy: 0.9276\n",
      "Validation performance after epoch 4: NLL: 0.2537, Accuracy: 0.9255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1b0e00ad15c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2378\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2324\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# may change to (mode, 0, 1) post-1.1.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m             im = im._new(\n\u001b[1;32m   2328\u001b[0m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     \"\"\"\n\u001b[1;32m   2216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m     \u001b[0m_check_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_check_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2189\u001b[0m     \"\"\"\n\u001b[1;32m   2190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2191\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2192\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size must be a tuple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "mlp = MLP(num_layers = 1)\n",
    "optim = torch.optim.SGD(mlp.parameters(), lr =0.5)\n",
    "num_epochs = 20\n",
    "for e in range(num_epochs):\n",
    "    for (image, label) in train_loader:\n",
    "        optim.zero_grad()\n",
    "        image, label = Variable(image), Variable(label) \n",
    "        y_pred = mlp(image)\n",
    "        nll_batch = criterion(y_pred, label)    \n",
    "        nll_batch.backward()\n",
    "        optim.step()\n",
    "    nll_train, accuracy_train = test(mlp, train_loader) #you never wanna do this in practice, since this will take forever\n",
    "    nll_val, accuracy_val = test(mlp, val_loader)\n",
    "    print('Training performance after epoch %d: NLL: %.4f, Accuracy: %.4f'% (e+1, nll_train, accuracy_train))\n",
    "    print('Validation performance after epoch %d: NLL: %.4f, Accuracy: %.4f'% (e+1, nll_val, accuracy_val))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with more hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_to_output): Linear(in_features=100, out_features=10)\n",
      "  (hidden_layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=100)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=100)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=100)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (logsoftmax): LogSoftmax()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoonkim/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance after epoch 1: NLL: 0.1355, Accuracy: 0.9587\n",
      "Validation performance after epoch 1: NLL: 0.1380, Accuracy: 0.9557\n",
      "Training performance after epoch 2: NLL: 0.1054, Accuracy: 0.9677\n",
      "Validation performance after epoch 2: NLL: 0.1329, Accuracy: 0.9601\n",
      "Training performance after epoch 3: NLL: 0.0678, Accuracy: 0.9786\n",
      "Validation performance after epoch 3: NLL: 0.0977, Accuracy: 0.9694\n",
      "Training performance after epoch 4: NLL: 0.0552, Accuracy: 0.9826\n",
      "Validation performance after epoch 4: NLL: 0.0988, Accuracy: 0.9696\n",
      "Training performance after epoch 5: NLL: 0.0357, Accuracy: 0.9887\n",
      "Validation performance after epoch 5: NLL: 0.0810, Accuracy: 0.9765\n",
      "Training performance after epoch 6: NLL: 0.0445, Accuracy: 0.9857\n",
      "Validation performance after epoch 6: NLL: 0.0929, Accuracy: 0.9736\n",
      "Training performance after epoch 7: NLL: 0.0362, Accuracy: 0.9884\n",
      "Validation performance after epoch 7: NLL: 0.0896, Accuracy: 0.9747\n",
      "Training performance after epoch 8: NLL: 0.0380, Accuracy: 0.9877\n",
      "Validation performance after epoch 8: NLL: 0.0919, Accuracy: 0.9754\n",
      "Training performance after epoch 9: NLL: 0.0202, Accuracy: 0.9935\n",
      "Validation performance after epoch 9: NLL: 0.0787, Accuracy: 0.9781\n",
      "Training performance after epoch 10: NLL: 0.0240, Accuracy: 0.9921\n",
      "Validation performance after epoch 10: NLL: 0.0894, Accuracy: 0.9758\n",
      "Training performance after epoch 11: NLL: 0.0142, Accuracy: 0.9954\n",
      "Validation performance after epoch 11: NLL: 0.0872, Accuracy: 0.9784\n",
      "Training performance after epoch 12: NLL: 0.0130, Accuracy: 0.9958\n",
      "Validation performance after epoch 12: NLL: 0.0926, Accuracy: 0.9776\n",
      "Training performance after epoch 13: NLL: 0.0150, Accuracy: 0.9951\n",
      "Validation performance after epoch 13: NLL: 0.0974, Accuracy: 0.9765\n",
      "Training performance after epoch 14: NLL: 0.0094, Accuracy: 0.9970\n",
      "Validation performance after epoch 14: NLL: 0.0903, Accuracy: 0.9788\n",
      "Training performance after epoch 15: NLL: 0.0224, Accuracy: 0.9931\n",
      "Validation performance after epoch 15: NLL: 0.1151, Accuracy: 0.9747\n",
      "Training performance after epoch 16: NLL: 0.0171, Accuracy: 0.9943\n",
      "Validation performance after epoch 16: NLL: 0.1114, Accuracy: 0.9762\n",
      "Training performance after epoch 17: NLL: 0.0171, Accuracy: 0.9946\n",
      "Validation performance after epoch 17: NLL: 0.1169, Accuracy: 0.9751\n",
      "Training performance after epoch 18: NLL: 0.0223, Accuracy: 0.9932\n",
      "Validation performance after epoch 18: NLL: 0.1245, Accuracy: 0.9738\n",
      "Training performance after epoch 19: NLL: 0.0087, Accuracy: 0.9976\n",
      "Validation performance after epoch 19: NLL: 0.1082, Accuracy: 0.9786\n",
      "Training performance after epoch 20: NLL: 0.0112, Accuracy: 0.9964\n",
      "Validation performance after epoch 20: NLL: 0.1162, Accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(num_layers = 3, hidden_dim = 100)\n",
    "print(mlp)\n",
    "optim = torch.optim.SGD(mlp.parameters(), lr = 0.5)\n",
    "num_epochs = 20\n",
    "for e in range(num_epochs):\n",
    "    for (image, label) in train_loader:\n",
    "        optim.zero_grad()\n",
    "        image, label = Variable(image), Variable(label) \n",
    "        y_pred = mlp(image)\n",
    "        nll_batch = criterion(y_pred, label)    \n",
    "        nll_batch.backward()\n",
    "        optim.step()\n",
    "    nll_train, accuracy_train = test(mlp, train_loader) \n",
    "    nll_val, accuracy_val = test(mlp, val_loader)\n",
    "    print('Training performance after epoch %d: NLL: %.4f, Accuracy: %.4f'% (e+1, nll_train, accuracy_train))\n",
    "    print('Validation performance after epoch %d: NLL: %.4f, Accuracy: %.4f'% (e+1, nll_val, accuracy_val))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. For the rest of section, try implementing a ConvNet. You may need to use more sophisticated optimization algorithms (`optim.Adam(model.parameters(), lr = 0.001)` should work well enough for most models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
